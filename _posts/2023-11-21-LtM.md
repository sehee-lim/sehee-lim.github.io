---
layout: post
title: "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"
category: "NLP"
date: 2023-11-21
---

<br>

기존의 Chain-of-Thought(CoT) prompting 기법은 주어진 예제보다 더 어려운 문제를 해결할 때 한계가 있었다. 따라서 CoT를 발전시킨 새로운 prompting 전략인 Least-to-Most 기법을 제시한다. 이 기법은 복잡한 문제를 더 간단한 부분 문제로 나누고 이를 차례대로 해결한다. 각 부분 문제를 해결하는 데에는 이전에 해결된 부분 문제들의 답변이 사용된다. 

<br>
<br>

두 단계 모두 few-shot prompting으로 시행된다.

**Stage 1: Decompose Question into Subquestions**

Few-shot 기법을 사용하기 때문에 문제와 그 문제를 분해한 부분 문제로 이루어진 예제들을 모델과 함께 제시한다. 그리고 우리가 해결하고자 하는 문제를 분해하라고 지시한다.

**Stage 2: Sequentially Solve Subquestions**

세 가지가 들어간다. 먼저 각 예제에 있는 부분 문제들에 대한 답변이 들어간다. 그리고 위에서 분해한 우리가 해결하고자 하는 문제의 부분 문제가 들어간다. 마지막으로 답변을 내기 위해 최종적으로 답변해야 하는 문제가 들어간다.

![Untitled](/assets/Least-to-Most%20Prompting%20Enables%20Complex%20Reasoning%20%20241b4c8467ae4fc195e5fb3f9d764a7b/Untitled.png)

<br>
<br>

paper

[https://arxiv.org/abs/2205.10625](https://arxiv.org/abs/2205.10625)