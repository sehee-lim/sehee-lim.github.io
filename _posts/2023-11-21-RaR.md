---
layout: post
title: "Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves"
category: "NLP"
date: 2023-11-21
---

<br>

Prompt의 품질에 따라 LLM 응답의 품질이 달라진다. 아래의 그림은 LLM이 제시된 질문에서 모호함을 어떻게 경험하는지 보여준다. 예를 들어 LLM은 even month가 일수가 짝수인 달을 의미하는 것인지, 아니면 달의 숫자가 짝수인 것을 물어보는 것인지 구분하지 못한다. 즉 질문에 모호함이 존재한다. 이러한 문제를 해결하기 위해 RaR 기법은 LLM에게 질문을 rephrase하게 함으로써 더 정확한 답변을 가능하게 한다. 이렇게 rephrase된 질문들은 질문의 의미를 더 명확하게 하고 모호성을 해결하여 LLM이 보다 정확하게 답변하도록 돕는다.

![Untitled](/assets/Rephrase%20and%20Respond%20Let%20Large%20Language%20Models%20Ask%20db0c36206a5b4d23b0f6c17aceaa53db/Untitled.png)

<br>
<br>


### **One-step RaR**



<img src="/assets/Rephrase%20and%20Respond%20Let%20Large%20Language%20Models%20Ask%20db0c36206a5b4d23b0f6c17aceaa53db/Untitled%201.png" alt="Untitled" class="center-image1">



LLM에게 제시하고 싶은 질문과 “Rephrase and expand the question, and respond.”라는 지시문을 준다. 그럼 LLM은 질문을 스스로 rephrase하고 그것에 따라서 답변을 준다.

<br>


### **Two-step RaR**

![Untitled](/assets/Rephrase%20and%20Respond%20Let%20Large%20Language%20Models%20Ask%20db0c36206a5b4d23b0f6c17aceaa53db/Untitled%202.png)



비슷하게 LLM에게 제시하고 싶은 질문을 rephrase하게 한다. 그 trigger 문장은 “Given the above question, rephrase and expand it to help you do better answering.”이다. 그럼 LLM은 새롭게 다듬은 질문을 내보낸다. 이제 원래 질문과 새롭게 만들어진 질문을 함께 묶어서 질문한다. 여기서 rephrase하게 하는 LLM과 답변을 내는 LLM은 다른 모델일 수 있다. 예를 들어 질문을 rephrase하게 하는 LLM은 GPT-4로 하고, 답변을 내는 LLM은 상대적으로 성능이 떨어지는 Vicuna를 쓸 수도 있다.

<br>
<br>


paper

[https://arxiv.org/abs/2311.04205](https://arxiv.org/abs/2311.04205)